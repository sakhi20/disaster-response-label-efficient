{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":14880791,"datasetId":9520580,"databundleVersionId":15743822},{"sourceType":"datasetVersion","sourceId":10321182,"datasetId":6390258,"databundleVersionId":10627025}],"dockerImageVersionId":31260,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install opencv-python numpy matplotlib tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:09:48.310660Z","iopub.execute_input":"2026-02-18T20:09:48.311027Z","iopub.status.idle":"2026-02-18T20:09:51.887232Z","shell.execute_reply.started":"2026-02-18T20:09:48.311006Z","shell.execute_reply":"2026-02-18T20:09:51.886519Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (26.0rc2)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\n\n# -----------------------------\n# CONFIG\n# -----------------------------\nIMAGE_DIR = \"/kaggle/input/xbd-dataset/xbd/tier1/images\"\nMASK_DIR  = \"/kaggle/input/xbd-dataset/xbd/tier1/masks\"\n\nPIXEL_DIFF_THRESHOLD = 30\n\n# Damage severity thresholds (ratio of changed pixels)\nSLIGHT_THR = 0.02\nMODERATE_THR = 0.10\n\n# -----------------------------\n# FUNCTIONS\n# -----------------------------\ndef load_gray(path):\n    img = cv2.imread(path)\n    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\ndef compute_change_binary(pre, post):\n    diff = cv2.absdiff(post, pre)\n    diff = cv2.GaussianBlur(diff, (5, 5), 0)\n    _, binary = cv2.threshold(diff, PIXEL_DIFF_THRESHOLD, 255, cv2.THRESH_BINARY)\n    return binary\n\ndef damage_severity(change_ratio):\n    if change_ratio < SLIGHT_THR:\n        return 0  # No / Very slight\n    elif change_ratio < MODERATE_THR:\n        return 1  # Moderate\n    else:\n        return 2  # High\n\ndef load_mask(mask_path):\n    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n    return (mask > 0).astype(np.uint8)\n\ndef iou_score(pred, gt):\n    intersection = np.logical_and(pred, gt).sum()\n    union = np.logical_or(pred, gt).sum()\n    return intersection / union if union != 0 else 1.0\n\n# -----------------------------\n# PAIR IMAGES\n# -----------------------------\nfiles = os.listdir(IMAGE_DIR)\n\npre_imgs, post_imgs = {}, {}\nfor f in files:\n    if \"pre\" in f:\n        key = f.replace(\"_pre_disaster.png\", \"\")\n        pre_imgs[key] = f\n    elif \"post\" in f:\n        key = f.replace(\"_post_disaster.png\", \"\")\n        post_imgs[key] = f\n\nkeys = list(set(pre_imgs.keys()) & set(post_imgs.keys()))\n\n# -----------------------------\n# METRICS\n# -----------------------------\ncorrect = 0\ntotal = 0\nious = []\n\n# -----------------------------\n# PROCESS\n# -----------------------------\nfor key in tqdm(keys):\n    pre = load_gray(os.path.join(IMAGE_DIR, pre_imgs[key]))\n    post = load_gray(os.path.join(IMAGE_DIR, post_imgs[key]))\n\n    change_binary = compute_change_binary(pre, post)\n    change_ratio = np.count_nonzero(change_binary) / change_binary.size\n    pred_severity = damage_severity(change_ratio)\n\n    # ---- Ground Truth from mask ----\n    mask_path = os.path.join(MASK_DIR, key + \"_post_disaster.png\")\n    if not os.path.exists(mask_path):\n        continue\n\n    gt_mask = load_mask(mask_path)\n    gt_ratio = gt_mask.sum() / gt_mask.size\n    gt_severity = damage_severity(gt_ratio)\n\n    # ---- Accuracy ----\n    if pred_severity == gt_severity:\n        correct += 1\n    total += 1\n\n    # ---- IoU ----\n    ious.append(iou_score(change_binary > 0, gt_mask))\n\n# -----------------------------\n# RESULTS\n# -----------------------------\naccuracy = correct / total if total > 0 else 0\nmean_iou = np.mean(ious)\n\nprint(f\"Classification Accuracy: {accuracy:.3f}\")\nprint(f\"Mean IoU: {mean_iou:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:09:51.889045Z","iopub.execute_input":"2026-02-18T20:09:51.889241Z","iopub.status.idle":"2026-02-18T20:14:30.189592Z","shell.execute_reply.started":"2026-02-18T20:09:51.889220Z","shell.execute_reply":"2026-02-18T20:14:30.188617Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 2799/2799 [04:38<00:00, 10.07it/s]","output_type":"stream"},{"name":"stdout","text":"Classification Accuracy: 0.243\nMean IoU: 0.057\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"PIXEL_DIFF_THRESHOLDS = [10, 20, 30, 40, 50]\n\nresults_pixel = []\n\nfor pix_thr in PIXEL_DIFF_THRESHOLDS:\n    correct, total, ious = 0, 0, []\n\n    print(f\"\\nRunning for PIXEL_DIFF_THRESHOLD = {pix_thr}\")\n\n    for key in tqdm(keys, desc=f\"PixelThr={pix_thr}\", leave=False):\n        pre = load_gray(os.path.join(IMAGE_DIR, pre_imgs[key]))\n        post = load_gray(os.path.join(IMAGE_DIR, post_imgs[key]))\n\n        diff = cv2.absdiff(post, pre)\n        diff = cv2.GaussianBlur(diff, (5, 5), 0)\n        _, change_binary = cv2.threshold(diff, pix_thr, 255, cv2.THRESH_BINARY)\n\n        change_ratio = np.count_nonzero(change_binary) / change_binary.size\n        pred_severity = damage_severity(change_ratio)\n\n        mask_path = os.path.join(MASK_DIR, key + \"_post_disaster.png\")\n        if not os.path.exists(mask_path):\n            continue\n\n        gt_mask = load_mask(mask_path)\n        gt_ratio = gt_mask.sum() / gt_mask.size\n        gt_severity = damage_severity(gt_ratio)\n\n        if pred_severity == gt_severity:\n            correct += 1\n        total += 1\n        ious.append(iou_score(change_binary > 0, gt_mask))\n\n    acc = correct / total\n    miou = np.mean(ious)\n\n    results_pixel.append((pix_thr, acc, miou))\n    print(f\"PixelThr={pix_thr} | Accuracy={acc:.3f} | Mean IoU={miou:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:14:30.190532Z","iopub.execute_input":"2026-02-18T20:14:30.190848Z","iopub.status.idle":"2026-02-18T20:32:18.623492Z","shell.execute_reply.started":"2026-02-18T20:14:30.190821Z","shell.execute_reply":"2026-02-18T20:32:18.622630Z"}},"outputs":[{"name":"stdout","text":"\nRunning for PIXEL_DIFF_THRESHOLD = 10\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"PixelThr=10 | Accuracy=0.209 | Mean IoU=0.062\n\nRunning for PIXEL_DIFF_THRESHOLD = 20\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"PixelThr=20 | Accuracy=0.213 | Mean IoU=0.061\n\nRunning for PIXEL_DIFF_THRESHOLD = 30\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"PixelThr=30 | Accuracy=0.243 | Mean IoU=0.057\n\nRunning for PIXEL_DIFF_THRESHOLD = 40\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"PixelThr=40 | Accuracy=0.306 | Mean IoU=0.054\n\nRunning for PIXEL_DIFF_THRESHOLD = 50\n","output_type":"stream"},{"name":"stderr","text":"                                                                ","output_type":"stream"},{"name":"stdout","text":"PixelThr=50 | Accuracy=0.395 | Mean IoU=0.049\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"SEVERITY_THRESHOLDS = [\n    (0.01, 0.05),\n    (0.02, 0.10),\n    (0.05, 0.15),\n    (0.05, 0.20),\n]\n\nresults_severity = []\n\nfor slight_thr, moderate_thr in SEVERITY_THRESHOLDS:\n    SLIGHT_THR = slight_thr\n    MODERATE_THR = moderate_thr\n\n    correct, total, ious = 0, 0, []\n\n    print(f\"\\nRunning for SLIGHT<{SLIGHT_THR}, MODERATE<{MODERATE_THR}\")\n\n    for key in tqdm(keys, desc=f\"S={SLIGHT_THR},M={MODERATE_THR}\", leave=False):\n        pre = load_gray(os.path.join(IMAGE_DIR, pre_imgs[key]))\n        post = load_gray(os.path.join(IMAGE_DIR, post_imgs[key]))\n\n        change_binary = compute_change_binary(pre, post)\n        change_ratio = np.count_nonzero(change_binary) / change_binary.size\n        pred_severity = damage_severity(change_ratio)\n\n        mask_path = os.path.join(MASK_DIR, key + \"_post_disaster.png\")\n        if not os.path.exists(mask_path):\n            continue\n\n        gt_mask = load_mask(mask_path)\n        gt_ratio = gt_mask.sum() / gt_mask.size\n        gt_severity = damage_severity(gt_ratio)\n\n        if pred_severity == gt_severity:\n            correct += 1\n        total += 1\n        ious.append(iou_score(change_binary > 0, gt_mask))\n\n    acc = correct / total\n    miou = np.mean(ious)\n\n    results_severity.append((slight_thr, moderate_thr, acc, miou))\n    print(f\"Slight<{slight_thr}, Moderate<{moderate_thr} | Acc={acc:.3f} | IoU={miou:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:32:18.624531Z","iopub.execute_input":"2026-02-18T20:32:18.624757Z","iopub.status.idle":"2026-02-18T20:46:22.780209Z","shell.execute_reply.started":"2026-02-18T20:32:18.624735Z","shell.execute_reply":"2026-02-18T20:46:22.779481Z"}},"outputs":[{"name":"stdout","text":"\nRunning for SLIGHT<0.01, MODERATE<0.05\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Slight<0.01, Moderate<0.05 | Acc=0.326 | IoU=0.057\n\nRunning for SLIGHT<0.02, MODERATE<0.1\n","output_type":"stream"},{"name":"stderr","text":"                                                                 \r","output_type":"stream"},{"name":"stdout","text":"Slight<0.02, Moderate<0.1 | Acc=0.243 | IoU=0.057\n\nRunning for SLIGHT<0.05, MODERATE<0.15\n","output_type":"stream"},{"name":"stderr","text":"                                                                  \r","output_type":"stream"},{"name":"stdout","text":"Slight<0.05, Moderate<0.15 | Acc=0.216 | IoU=0.057\n\nRunning for SLIGHT<0.05, MODERATE<0.2\n","output_type":"stream"},{"name":"stderr","text":"                                                                 ","output_type":"stream"},{"name":"stdout","text":"Slight<0.05, Moderate<0.2 | Acc=0.223 | IoU=0.057\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Siamese U-Net","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport cv2\nfrom torch.utils.data import Dataset\n\nclass XBDDataset(Dataset):\n    def __init__(self, image_dir, mask_dir, transform=None):\n        self.image_dir = image_dir\n        self.mask_dir = mask_dir\n        self.transform = transform\n\n        self.pre_imgs = {}\n        self.post_imgs = {}\n\n        for f in os.listdir(image_dir):\n            if \"pre\" in f:\n                key = f.replace(\"_pre_disaster.png\", \"\")\n                self.pre_imgs[key] = f\n            elif \"post\" in f:\n                key = f.replace(\"_post_disaster.png\", \"\")\n                self.post_imgs[key] = f\n\n        self.keys = list(set(self.pre_imgs) & set(self.post_imgs))\n\n    def __len__(self):\n        return len(self.keys)\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n\n        pre = cv2.imread(os.path.join(self.image_dir, self.pre_imgs[key]))\n        post = cv2.imread(os.path.join(self.image_dir, self.post_imgs[key]))\n        mask = cv2.imread(os.path.join(self.mask_dir, key + \"_post_disaster.png\"), 0)\n\n        pre = cv2.cvtColor(pre, cv2.COLOR_BGR2RGB)\n        post = cv2.cvtColor(post, cv2.COLOR_BGR2RGB)\n        mask = (mask > 0).astype(\"float32\")\n\n        pre = torch.tensor(pre).permute(2, 0, 1) / 255.0\n        post = torch.tensor(post).permute(2, 0, 1) / 255.0\n        mask = torch.tensor(mask).unsqueeze(0)\n\n        return pre, post, mask\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:22.781027Z","iopub.execute_input":"2026-02-18T20:46:22.781295Z","iopub.status.idle":"2026-02-18T20:46:26.485111Z","shell.execute_reply.started":"2026-02-18T20:46:22.781243Z","shell.execute_reply":"2026-02-18T20:46:26.484093Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch.nn as nn\n\nclass ConvBlock(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.486079Z","iopub.execute_input":"2026-02-18T20:46:26.486446Z","iopub.status.idle":"2026-02-18T20:46:26.491774Z","shell.execute_reply.started":"2026-02-18T20:46:26.486421Z","shell.execute_reply":"2026-02-18T20:46:26.490878Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class SiameseUNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # Shared encoder\n        self.enc1 = ConvBlock(3, 64)\n        self.enc2 = ConvBlock(64, 128)\n        self.enc3 = ConvBlock(128, 256)\n\n        self.pool = nn.MaxPool2d(2)\n\n        # Decoder\n        self.up2 = nn.ConvTranspose2d(512, 128, 2, stride=2)\n        self.dec2 = ConvBlock(384, 128)\n\n        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n        self.dec1 = ConvBlock(192, 64)\n\n        self.final = nn.Conv2d(64, 1, 1)\n\n    def forward(self, pre, post):\n        # Encoder (shared)\n        p1 = self.enc1(pre)\n        p2 = self.enc2(self.pool(p1))\n        p3 = self.enc3(self.pool(p2))\n\n        q1 = self.enc1(post)\n        q2 = self.enc2(self.pool(q1))\n        q3 = self.enc3(self.pool(q2))\n\n        # Feature fusion\n        f3 = torch.cat([p3, q3], dim=1)\n\n        # Decoder\n        d2 = self.up2(f3)\n        d2 = self.dec2(torch.cat([d2, p2, q2], dim=1))\n\n        d1 = self.up1(d2)\n        d1 = self.dec1(torch.cat([d1, p1, q1], dim=1))\n\n        return torch.sigmoid(self.final(d1))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.492957Z","iopub.execute_input":"2026-02-18T20:46:26.493237Z","iopub.status.idle":"2026-02-18T20:46:26.507977Z","shell.execute_reply.started":"2026-02-18T20:46:26.493216Z","shell.execute_reply":"2026-02-18T20:46:26.506560Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"\n\nmodel = SiameseUNet().cuda()\n# model = SiameseUNet()\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.510374Z","iopub.execute_input":"2026-02-18T20:46:26.510678Z","iopub.status.idle":"2026-02-18T20:46:26.613627Z","shell.execute_reply.started":"2026-02-18T20:46:26.510652Z","shell.execute_reply":"2026-02-18T20:46:26.610174Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2354636912.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSiameseUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# model = SiameseUNet()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \"\"\"\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \"\"\"\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"],"ename":"RuntimeError","evalue":"Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"# import torch\n# torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.614163Z","iopub.status.idle":"2026-02-18T20:46:26.614427Z","shell.execute_reply.started":"2026-02-18T20:46:26.614313Z","shell.execute_reply":"2026-02-18T20:46:26.614328Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from torch.utils.data import DataLoader\n# import torch.optim as optim\n# import torch\n\n# dataset = XBDDataset(\n#     image_dir=\"/kaggle/input/xbd-dataset/xbd/tier1/images\",\n#     mask_dir=\"/kaggle/input/xbd-dataset/xbd/tier1/masks\"\n# )\n\n# loader = DataLoader(dataset, batch_size=1, shuffle=True)\n\n\n# criterion = nn.BCELoss()\n# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n# for epoch in range(10):\n#     model.train()\n#     epoch_loss = 0\n\n#     for pre, post, mask in loader:\n#         pre, post, mask = pre.cuda(), post.cuda(), mask.cuda()\n\n#         pred = model(pre, post)\n#         loss = criterion(pred, mask)\n\n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n\n#         epoch_loss += loss.item()\n\n#     print(f\"Epoch {epoch+1} | Loss: {epoch_loss/len(loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.615474Z","iopub.status.idle":"2026-02-18T20:46:26.615747Z","shell.execute_reply.started":"2026-02-18T20:46:26.615620Z","shell.execute_reply":"2026-02-18T20:46:26.615634Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport torch.optim as optim\nimport torch\nimport torch.nn as nn\nfrom tqdm import tqdm\n\ndataset = XBDDataset(\n    image_dir=\"/kaggle/input/xbd-dataset/xbd/tier1/images\",\n    mask_dir=\"/kaggle/input/xbd-dataset/xbd/tier1/masks\"\n)\n\nloader = DataLoader(\n    dataset,\n    batch_size=1,\n    shuffle=True,\n    num_workers=2,       # safe for Kaggle\n    pin_memory=True      # helps GPU transfer\n)\n\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nfor epoch in range(10):\n    model.train()\n    epoch_loss = 0.0\n\n    progress_bar = tqdm(\n        loader,\n        desc=f\"Epoch [{epoch+1}/10]\",\n        leave=False\n    )\n\n    for pre, post, mask in progress_bar:\n        pre  = pre.to(device, non_blocking=True)\n        post = post.to(device, non_blocking=True)\n        mask = mask.to(device, non_blocking=True)\n\n        optimizer.zero_grad()\n\n        pred = model(pre, post)\n        loss = criterion(pred, mask)\n\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n        progress_bar.set_postfix(\n            loss=f\"{epoch_loss / (progress_bar.n + 1):.4f}\"\n        )\n\n    print(f\"Epoch {epoch+1} | Avg Loss: {epoch_loss / len(loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.616243Z","iopub.status.idle":"2026-02-18T20:46:26.616485Z","shell.execute_reply.started":"2026-02-18T20:46:26.616376Z","shell.execute_reply":"2026-02-18T20:46:26.616389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\navg_loss = [0.1837, 0.0958, 0.0810, 0.0728, 0.0693, 0.0647, 0.0620, 0.0604, 0.0587, 0.0566]\nx = [a for a in range(1,11)]\n\nplt.plot(x, avg_loss)\nplt.title(\"Training loss for Siamese UNet\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.617116Z","iopub.status.idle":"2026-02-18T20:46:26.617383Z","shell.execute_reply.started":"2026-02-18T20:46:26.617234Z","shell.execute_reply":"2026-02-18T20:46:26.617249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nsave_path = \"/kaggle/working/siamese_unet_xbd.pth\"\n\n# Move model to CPU before saving (avoids GPU-specific issues)\nmodel_cpu = model.to(\"cpu\")\n\ntorch.save(\n    {\n        \"model_state_dict\": model_cpu.state_dict(),\n        \"optimizer_state_dict\": optimizer.state_dict(),\n        \"epochs\": 10\n    },\n    save_path\n)\n\nprint(f\"Model saved to {save_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.618563Z","iopub.status.idle":"2026-02-18T20:46:26.618768Z","shell.execute_reply.started":"2026-02-18T20:46:26.618671Z","shell.execute_reply":"2026-02-18T20:46:26.618683Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_params = sum(p.numel() for p in model.parameters()) * 4 / 1024**2\n\nprint(\"Model parameter size is(in MB):\", model_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.619578Z","iopub.status.idle":"2026-02-18T20:46:26.619842Z","shell.execute_reply.started":"2026-02-18T20:46:26.619733Z","shell.execute_reply":"2026-02-18T20:46:26.619750Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing on trained model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\nclass ConvBlock(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.620626Z","iopub.status.idle":"2026-02-18T20:46:26.620881Z","shell.execute_reply.started":"2026-02-18T20:46:26.620774Z","shell.execute_reply":"2026-02-18T20:46:26.620790Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SiameseUNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # Shared encoder\n        self.enc1 = ConvBlock(3, 64)\n        self.enc2 = ConvBlock(64, 128)\n        self.enc3 = ConvBlock(128, 256)\n\n        self.pool = nn.MaxPool2d(2)\n\n        # Decoder\n        self.up2 = nn.ConvTranspose2d(512, 128, 2, stride=2)\n        self.dec2 = ConvBlock(384, 128)\n\n        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n        self.dec1 = ConvBlock(192, 64)\n\n        self.final = nn.Conv2d(64, 1, 1)\n\n    def forward(self, pre, post):\n        # Encoder (shared)\n        p1 = self.enc1(pre)\n        p2 = self.enc2(self.pool(p1))\n        p3 = self.enc3(self.pool(p2))\n\n        q1 = self.enc1(post)\n        q2 = self.enc2(self.pool(q1))\n        q3 = self.enc3(self.pool(q2))\n\n        # Feature fusion\n        f3 = torch.cat([p3, q3], dim=1)\n\n        # Decoder\n        d2 = self.up2(f3)\n        d2 = self.dec2(torch.cat([d2, p2, q2], dim=1))\n\n        d1 = self.up1(d2)\n        d1 = self.dec1(torch.cat([d1, p1, q1], dim=1))\n\n        return torch.sigmoid(self.final(d1))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.621844Z","iopub.status.idle":"2026-02-18T20:46:26.622102Z","shell.execute_reply.started":"2026-02-18T20:46:26.621978Z","shell.execute_reply":"2026-02-18T20:46:26.621996Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# model = SiameseUNet().to(device)\n# print(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.623040Z","iopub.status.idle":"2026-02-18T20:46:26.623302Z","shell.execute_reply.started":"2026-02-18T20:46:26.623168Z","shell.execute_reply":"2026-02-18T20:46:26.623183Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ncheckpoint = torch.load(\"/kaggle/input/datasets/draqa123/siamese-unet/siamese_unet_xbd.pth\", map_location=device)\n\nmodel = SiameseUNet().to(device)\nmodel.load_state_dict(checkpoint[\"model_state_dict\"])\n\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.624317Z","iopub.status.idle":"2026-02-18T20:46:26.624795Z","shell.execute_reply.started":"2026-02-18T20:46:26.624645Z","shell.execute_reply":"2026-02-18T20:46:26.624663Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Loaded successfully\")\nprint(sum(p.numel() for p in model.parameters()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.625675Z","iopub.status.idle":"2026-02-18T20:46:26.625948Z","shell.execute_reply.started":"2026-02-18T20:46:26.625807Z","shell.execute_reply":"2026-02-18T20:46:26.625825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport cv2\nfrom torch.utils.data import Dataset\n\nclass XBDDataset(Dataset):\n    def __init__(self, image_dir, mask_dir, transform=None):\n        self.image_dir = image_dir\n        self.mask_dir = mask_dir\n        self.transform = transform\n\n        self.pre_imgs = {}\n        self.post_imgs = {}\n\n        for f in os.listdir(image_dir):\n            if \"pre\" in f:\n                key = f.replace(\"_pre_disaster.png\", \"\")\n                self.pre_imgs[key] = f\n            elif \"post\" in f:\n                key = f.replace(\"_post_disaster.png\", \"\")\n                self.post_imgs[key] = f\n\n        self.keys = list(set(self.pre_imgs) & set(self.post_imgs))\n\n    def __len__(self):\n        return len(self.keys)\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n\n        pre = cv2.imread(os.path.join(self.image_dir, self.pre_imgs[key]))\n        post = cv2.imread(os.path.join(self.image_dir, self.post_imgs[key]))\n        mask = cv2.imread(os.path.join(self.mask_dir, key + \"_post_disaster.png\"), 0)\n\n        pre = cv2.cvtColor(pre, cv2.COLOR_BGR2RGB)\n        post = cv2.cvtColor(post, cv2.COLOR_BGR2RGB)\n        mask = (mask > 0).astype(\"float32\")\n\n        pre = torch.tensor(pre).permute(2, 0, 1) / 255.0\n        post = torch.tensor(post).permute(2, 0, 1) / 255.0\n        mask = torch.tensor(mask).unsqueeze(0)\n\n        return pre, post, mask\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.626799Z","iopub.status.idle":"2026-02-18T20:46:26.627092Z","shell.execute_reply.started":"2026-02-18T20:46:26.626931Z","shell.execute_reply":"2026-02-18T20:46:26.626948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = XBDDataset(\n    image_dir=\"/kaggle/input/xbd-dataset/xbd/tier1/images\",\n    mask_dir=\"/kaggle/input/xbd-dataset/xbd/tier1/masks\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.628666Z","iopub.status.idle":"2026-02-18T20:46:26.628959Z","shell.execute_reply.started":"2026-02-18T20:46:26.628846Z","shell.execute_reply":"2026-02-18T20:46:26.628862Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel.eval()\n\ntest_loader = DataLoader(\n    dataset,\n    batch_size=1,\n    shuffle=False\n)\n\nwith torch.no_grad():\n    for pre, post, mask in test_loader:\n\n        pre  = pre.to(device)\n        post = post.to(device)\n        mask = mask.to(device)\n\n        # Forward pass\n        pred = model(pre, post)\n\n        # Threshold\n        pred_mask = (pred > 0.5).float()\n\n        break   # only first test sample\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.629606Z","iopub.status.idle":"2026-02-18T20:46:26.629810Z","shell.execute_reply.started":"2026-02-18T20:46:26.629710Z","shell.execute_reply":"2026-02-18T20:46:26.629721Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\n\n# Pre-disaster image\nplt.subplot(1,4,1)\nplt.title(\"Pre Image\")\nplt.imshow(pre[0].cpu().permute(1,2,0))\nplt.axis(\"off\")\n\n# Post-disaster image\nplt.subplot(1,4,2)\nplt.title(\"Post Image\")\nplt.imshow(post[0].cpu().permute(1,2,0))\nplt.axis(\"off\")\n\n# Ground Truth Mask\nplt.subplot(1,4,3)\nplt.title(\"Ground Truth\")\nplt.imshow(mask[0].cpu().squeeze(), cmap=\"gray\")\nplt.axis(\"off\")\n\n# Predicted Mask\nplt.subplot(1,4,4)\nplt.title(\"Prediction\")\nplt.imshow(pred_mask[0].cpu().squeeze(), cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.630467Z","iopub.status.idle":"2026-02-18T20:46:26.630658Z","shell.execute_reply.started":"2026-02-18T20:46:26.630568Z","shell.execute_reply":"2026-02-18T20:46:26.630579Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel.eval()\n\ntest_loader = DataLoader(\n    dataset,\n    batch_size=1,\n    shuffle=False\n)\n\ntotal_dice = 0\ntotal_iou = 0\ntotal_correct = 0\ntotal_pixels = 0\n\nwith torch.no_grad():\n    for pre, post, mask in tqdm(test_loader):\n\n        pre  = pre.to(device)\n        post = post.to(device)\n        mask = mask.to(device)\n\n        # Forward\n        pred = model(pre, post)\n\n        pred_mask = (pred > 0.5).float()\n\n        # ---- Metrics ----\n\n        # Dice\n        intersection = (pred_mask * mask).sum()\n        dice = (2 * intersection) / (\n            pred_mask.sum() + mask.sum() + 1e-8\n        )\n\n        # IoU\n        union = pred_mask.sum() + mask.sum() - intersection\n        iou = intersection / (union + 1e-8)\n\n        # Pixel Accuracy\n        correct = (pred_mask == mask).sum()\n        total_correct += correct.item()\n        total_pixels += torch.numel(mask)\n\n        total_dice += dice.item()\n        total_iou += iou.item()\n\n# Final Results\nnum_samples = len(test_loader)\n\nprint(\"Evaluation Results:\")\nprint(\"Dice Score :\", total_dice / num_samples)\nprint(\"IoU        :\", total_iou / num_samples)\nprint(\"Pixel Acc  :\", total_correct / total_pixels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.632308Z","iopub.status.idle":"2026-02-18T20:46:26.632592Z","shell.execute_reply.started":"2026-02-18T20:46:26.632479Z","shell.execute_reply":"2026-02-18T20:46:26.632493Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with torch.no_grad():\n    pre, post, mask = next(iter(test_loader))\n\n    pre  = pre.to(device)\n    post = post.to(device)\n    mask = mask.to(device)\n\n    pred = model(pre, post)\n\n    print(\"Pred raw min/max:\", pred.min().item(), pred.max().item())\n    print(\"Mask min/max:\", mask.min().item(), mask.max().item())\n    print(\"Pred shape:\", pred.shape)\n    print(\"Mask shape:\", mask.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.633744Z","iopub.status.idle":"2026-02-18T20:46:26.634029Z","shell.execute_reply.started":"2026-02-18T20:46:26.633906Z","shell.execute_reply":"2026-02-18T20:46:26.633923Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Using SPAUnet","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.635170Z","iopub.status.idle":"2026-02-18T20:46:26.635436Z","shell.execute_reply.started":"2026-02-18T20:46:26.635327Z","shell.execute_reply":"2026-02-18T20:46:26.635342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class XBDDataset(Dataset):\n    def __init__(self, image_dir, mask_dir=None):\n        self.image_dir = image_dir\n        self.mask_dir = mask_dir\n\n        self.pre_imgs = {}\n        self.post_imgs = {}\n\n        for f in os.listdir(image_dir):\n            if \"pre_disaster\" in f:\n                key = f.replace(\"_pre_disaster.png\", \"\")\n                self.pre_imgs[key] = f\n            elif \"post_disaster\" in f:\n                key = f.replace(\"_post_disaster.png\", \"\")\n                self.post_imgs[key] = f\n\n        self.keys = sorted(list(set(self.pre_imgs) & set(self.post_imgs)))\n\n    def __len__(self):\n        return len(self.keys)\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n\n        pre = cv2.imread(os.path.join(self.image_dir, self.pre_imgs[key]))\n        post = cv2.imread(os.path.join(self.image_dir, self.post_imgs[key]))\n\n        pre = cv2.cvtColor(pre, cv2.COLOR_BGR2RGB)\n        post = cv2.cvtColor(post, cv2.COLOR_BGR2RGB)\n\n        pre = torch.tensor(pre).permute(2, 0, 1).float() / 255.0\n        post = torch.tensor(post).permute(2, 0, 1).float() / 255.0\n\n        if self.mask_dir:\n            mask_path = os.path.join(self.mask_dir, key + \"_post_disaster.png\")\n            mask = cv2.imread(mask_path, 0)\n            mask = torch.tensor(mask).long()\n            return pre, post, mask\n\n        return pre, post\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.636876Z","iopub.status.idle":"2026-02-18T20:46:26.637135Z","shell.execute_reply.started":"2026-02-18T20:46:26.637010Z","shell.execute_reply":"2026-02-18T20:46:26.637024Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tier1 = XBDDataset(\"/kaggle/input/xbd-dataset/xbd/tier1/images\", \"/kaggle/input/xbd-dataset/xbd/tier1/masks\")\ntier3 = XBDDataset(\"/kaggle/input/xbd-dataset/xbd/tier3/images\", \"/kaggle/input/xbd-dataset/xbd/tier3/masks\")\n\nfull_labeled = torch.utils.data.ConcatDataset([tier1, tier3])\n\ntotal_len = len(full_labeled)\nlabeled_len = int(0.2 * total_len)\n\nlabeled_dataset, _ = random_split(\n    full_labeled,\n    [labeled_len, total_len - labeled_len]\n)\n\nval_dataset = XBDDataset(\"/kaggle/input/xbd-dataset/xbd/hold/images\", \"/kaggle/input/xbd-dataset/xbd/hold/masks\")\n\nlabeled_loader = DataLoader(labeled_dataset, batch_size=8, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=8)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.637789Z","iopub.status.idle":"2026-02-18T20:46:26.637977Z","shell.execute_reply.started":"2026-02-18T20:46:26.637885Z","shell.execute_reply":"2026-02-18T20:46:26.637896Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# model arch.","metadata":{}},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.639186Z","iopub.status.idle":"2026-02-18T20:46:26.639534Z","shell.execute_reply.started":"2026-02-18T20:46:26.639377Z","shell.execute_reply":"2026-02-18T20:46:26.639396Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SPABlock(nn.Module):\n    def __init__(self, in_ch):\n        super().__init__()\n\n        self.pool1 = nn.AdaptiveAvgPool2d(1)\n        self.pool2 = nn.AdaptiveAvgPool2d(2)\n        self.pool3 = nn.AdaptiveAvgPool2d(4)\n\n        self.conv = nn.Conv2d(in_ch * 3, in_ch, 1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        h, w = x.shape[2:]\n\n        p1 = F.interpolate(self.pool1(x), size=(h, w), mode='bilinear')\n        p2 = F.interpolate(self.pool2(x), size=(h, w), mode='bilinear')\n        p3 = F.interpolate(self.pool3(x), size=(h, w), mode='bilinear')\n\n        out = torch.cat([p1, p2, p3], dim=1)\n        attention = self.sigmoid(self.conv(out))\n\n        return x * attention\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.640510Z","iopub.status.idle":"2026-02-18T20:46:26.640821Z","shell.execute_reply.started":"2026-02-18T20:46:26.640657Z","shell.execute_reply":"2026-02-18T20:46:26.640675Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.enc1 = DoubleConv(3, 64)\n        self.enc2 = DoubleConv(64, 128)\n        self.enc3 = DoubleConv(128, 256)\n        self.enc4 = DoubleConv(256, 512)\n\n        self.pool = nn.MaxPool2d(2)\n\n    def forward(self, x):\n        x1 = self.enc1(x)\n        x2 = self.enc2(self.pool(x1))\n        x3 = self.enc3(self.pool(x2))\n        x4 = self.enc4(self.pool(x3))\n        return x1, x2, x3, x4\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.641444Z","iopub.status.idle":"2026-02-18T20:46:26.641765Z","shell.execute_reply.started":"2026-02-18T20:46:26.641605Z","shell.execute_reply":"2026-02-18T20:46:26.641622Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class UpBlock(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.up = nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2)\n        self.conv = DoubleConv(in_ch, out_ch)\n\n    def forward(self, x, skip):\n        x = self.up(x)\n        x = torch.cat([x, skip], dim=1)\n        return self.conv(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.642394Z","iopub.status.idle":"2026-02-18T20:46:26.642608Z","shell.execute_reply.started":"2026-02-18T20:46:26.642503Z","shell.execute_reply":"2026-02-18T20:46:26.642518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SPAUNet(nn.Module):\n    def __init__(self, num_classes=5):\n        super().__init__()\n\n        self.encoder = Encoder()\n        self.spa = SPABlock(512)\n\n        self.up3 = UpBlock(512, 256)\n        self.up2 = UpBlock(256, 128)\n        self.up1 = UpBlock(128, 64)\n\n        self.final = nn.Conv2d(64, num_classes, 1)\n\n    def forward(self, pre, post):\n        p1, p2, p3, p4 = self.encoder(pre)\n        q1, q2, q3, q4 = self.encoder(post)\n\n        f1 = torch.abs(p1 - q1)\n        f2 = torch.abs(p2 - q2)\n        f3 = torch.abs(p3 - q3)\n        f4 = torch.abs(p4 - q4)\n\n        bottleneck = self.spa(f4)\n\n        d3 = self.up3(bottleneck, f3)\n        d2 = self.up2(d3, f2)\n        d1 = self.up1(d2, f1)\n\n        return self.final(d1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.643249Z","iopub.status.idle":"2026-02-18T20:46:26.643473Z","shell.execute_reply.started":"2026-02-18T20:46:26.643378Z","shell.execute_reply":"2026-02-18T20:46:26.643391Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_iou(pred, mask, num_classes=5):\n    ious = []\n    pred = torch.argmax(pred, dim=1)\n\n    for cls in range(num_classes):\n        pred_cls = (pred == cls)\n        mask_cls = (mask == cls)\n\n        intersection = (pred_cls & mask_cls).sum().float()\n        union = (pred_cls | mask_cls).sum().float()\n\n        if union == 0:\n            continue\n\n        ious.append(intersection / union)\n\n    return torch.mean(torch.stack(ious))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.644138Z","iopub.status.idle":"2026-02-18T20:46:26.644358Z","shell.execute_reply.started":"2026-02-18T20:46:26.644234Z","shell.execute_reply":"2026-02-18T20:46:26.644245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nsave_dir = \"/kaggle/working/checkpoints\"\nos.makedirs(save_dir, exist_ok=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.645057Z","iopub.status.idle":"2026-02-18T20:46:26.645326Z","shell.execute_reply.started":"2026-02-18T20:46:26.645183Z","shell.execute_reply":"2026-02-18T20:46:26.645198Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_iou = 0\nstart_epoch = 0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.645902Z","iopub.status.idle":"2026-02-18T20:46:26.646156Z","shell.execute_reply.started":"2026-02-18T20:46:26.646030Z","shell.execute_reply":"2026-02-18T20:46:26.646049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"resume_path = os.path.join(save_dir, \"last_model.pth\")\n\nif os.path.exists(resume_path):\n    print(\"Resuming training...\")\n    checkpoint = torch.load(resume_path)\n    model.load_state_dict(checkpoint[\"model_state\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n    start_epoch = checkpoint[\"epoch\"]\n    best_iou = checkpoint[\"best_iou\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.646981Z","iopub.status.idle":"2026-02-18T20:46:26.647251Z","shell.execute_reply.started":"2026-02-18T20:46:26.647108Z","shell.execute_reply":"2026-02-18T20:46:26.647124Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = SPAUNet(num_classes=5).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\nepochs = 30\n\nfor epoch in range(start_epoch, epochs):\n\n    model.train()\n    train_loss = 0\n\n    for pre, post, mask in tqdm(labeled_loader):\n        pre = pre.to(device)\n        post = post.to(device)\n        mask = mask.to(device)\n\n        optimizer.zero_grad()\n        output = model(pre, post)\n        loss = criterion(output, mask)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    model.eval()\n    val_iou = 0\n\n    with torch.no_grad():\n        for pre, post, mask in val_loader:\n            pre = pre.to(device)\n            post = post.to(device)\n            mask = mask.to(device)\n\n            output = model(pre, post)\n            val_iou += compute_iou(output, mask).item()\n\n    val_iou /= len(val_loader)\n\n    print(f\"\\nEpoch {epoch+1}\")\n    print(f\"Train Loss: {train_loss/len(labeled_loader):.4f}\")\n    print(f\"Val mIoU: {val_iou:.4f}\")\n\n    # 🔹 Save Last Model Every Epoch\n    torch.save({\n        \"epoch\": epoch + 1,\n        \"model_state\": model.state_dict(),\n        \"optimizer_state\": optimizer.state_dict(),\n        \"best_iou\": best_iou\n    }, os.path.join(save_dir, \"last_model.pth\"))\n\n    # 🔹 Save Best Model\n    if val_iou > best_iou:\n        best_iou = val_iou\n        torch.save(model.state_dict(),\n                   os.path.join(save_dir, \"best_model.pth\"))\n        print(\"✅ Saved Best Model\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T20:46:26.649151Z","iopub.status.idle":"2026-02-18T20:46:26.649493Z","shell.execute_reply.started":"2026-02-18T20:46:26.649351Z","shell.execute_reply":"2026-02-18T20:46:26.649371Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}